{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MuseGan_predict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPoBWOSYuRxexrQzVzRW9bW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Han1018/BeatGAN/blob/GenerateMidiAPI/MuseGan_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn093Wwj6bi7"
      },
      "source": [
        "### 導入雲端硬碟"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Twq9ReH06bJC",
        "outputId": "b74c75ab-2cce-4a4b-aafb-d1e7a7ea6626"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yCyy19h6keA"
      },
      "source": [
        "### 下載必備套件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YCyssHc6hiQ",
        "outputId": "9b8facf0-5790-4871-8fd1-83ad381f2853"
      },
      "source": [
        "!pip install pypianoroll==0.4.6\n",
        "!pip install tf-nightly\n",
        "!pip install gast==0.2.0\n",
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pypianoroll==0.4.6\n",
            "  Downloading pypianoroll-0.4.6.tar.gz (18 kB)\n",
            "Requirement already satisfied: six<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll==0.4.6) (1.19.5)\n",
            "Requirement already satisfied: scipy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll==0.4.6) (1.4.1)\n",
            "Collecting pretty_midi<1.0,>=0.2.8\n",
            "  Downloading pretty_midi-0.2.9.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 16.6 MB/s \n",
            "\u001b[?25hCollecting mido>=1.1.16\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 5.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pypianoroll, pretty-midi\n",
            "  Building wheel for pypianoroll (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypianoroll: filename=pypianoroll-0.4.6-py3-none-any.whl size=20977 sha256=5757f9c0858c82d941c9635db3e2eb3744d36d875025733ddc3ee40e884f3c8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/ec/3b/4768365c13867b24acf342ae0b91d782b448e2d78039bbde0d\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-py3-none-any.whl size=5591953 sha256=07edfbcc99a3db98cb1b3b054d61e96b68ff73105e54a483327126d1096b6698\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/74/7c/a06473ca8dcb63efb98c1e67667ce39d52100f837835ea18fa\n",
            "Successfully built pypianoroll pretty-midi\n",
            "Installing collected packages: mido, pretty-midi, pypianoroll\n",
            "Successfully installed mido-1.2.10 pretty-midi-0.2.9 pypianoroll-0.4.6\n",
            "Collecting tf-nightly\n",
            "  Downloading tf_nightly-2.7.0.dev20210815-cp37-cp37m-manylinux2010_x86_64.whl (468.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 468.2 MB 29 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.37.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.17.3)\n",
            "Collecting tb-nightly~=2.7.0.a\n",
            "  Downloading tb_nightly-2.7.0a20210813-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 62.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.12.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.2)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.20.0\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.20.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 25.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.4.0)\n",
            "Collecting tf-estimator-nightly~=2.7.0.dev\n",
            "  Downloading tf_estimator_nightly-2.7.0.dev2021081508-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 71.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.7.4.3)\n",
            "Collecting keras-nightly~=2.7.0.dev\n",
            "  Downloading keras_nightly-2.7.0.dev2021081507-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 37.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.19.5)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n",
            "Collecting libclang~=11.1.0\n",
            "  Downloading libclang-11.1.0-py2.py3-none-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 22.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n",
            "Collecting grpcio<2.0,>=1.37.0\n",
            "  Downloading grpcio-1.39.0-cp37-cp37m-manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 46.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tf-nightly) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (57.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (1.34.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (0.4.5)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.7.0.a->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.7.0.a->tf-nightly) (4.6.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.7.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.7.0.a->tf-nightly) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.7.0.a->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.7.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.7.0.a->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly~=2.7.0.a->tf-nightly) (3.5.0)\n",
            "Installing collected packages: grpcio, tf-estimator-nightly, tensorflow-io-gcs-filesystem, tb-nightly, libclang, keras-nightly, tf-nightly\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.34.1\n",
            "    Uninstalling grpcio-1.34.1:\n",
            "      Successfully uninstalled grpcio-1.34.1\n",
            "  Attempting uninstall: keras-nightly\n",
            "    Found existing installation: keras-nightly 2.5.0.dev2021032900\n",
            "    Uninstalling keras-nightly-2.5.0.dev2021032900:\n",
            "      Successfully uninstalled keras-nightly-2.5.0.dev2021032900\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.5.0 requires grpcio~=1.34.0, but you have grpcio 1.39.0 which is incompatible.\n",
            "tensorflow 2.5.0 requires keras-nightly~=2.5.0.dev, but you have keras-nightly 2.7.0.dev2021081507 which is incompatible.\u001b[0m\n",
            "Successfully installed grpcio-1.39.0 keras-nightly-2.7.0.dev2021081507 libclang-11.1.0 tb-nightly-2.7.0a20210813 tensorflow-io-gcs-filesystem-0.20.0 tf-estimator-nightly-2.7.0.dev2021081508 tf-nightly-2.7.0.dev20210815\n",
            "Collecting gast==0.2.0\n",
            "  Downloading gast-0.2.0.tar.gz (9.4 kB)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.0-py3-none-any.whl size=6664 sha256=a5a8654a742bc7c4d477c79c7ba67a35f7d1a1f6004c3edf472f69234928450a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/5c/7c/fa61262218d07604f2d0cf2021093ca599fa7d2df22ff27bb7\n",
            "Successfully built gast\n",
            "Installing collected packages: gast\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-nightly 2.7.0.dev20210815 requires gast==0.4.0, but you have gast 0.2.0 which is incompatible.\n",
            "tensorflow 2.5.0 requires gast==0.4.0, but you have gast 0.2.0 which is incompatible.\n",
            "tensorflow 2.5.0 requires grpcio~=1.34.0, but you have grpcio 1.39.0 which is incompatible.\n",
            "tensorflow 2.5.0 requires keras-nightly~=2.5.0.dev, but you have keras-nightly 2.7.0.dev2021081507 which is incompatible.\n",
            "tensorflow-probability 0.13.0 requires gast>=0.3.2, but you have gast 0.2.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONCSUMnN6qzO"
      },
      "source": [
        "### 載入一代tf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i8Ag9kM6of9",
        "outputId": "ab9d2c9c-16e2-463e-ea35-d3a066f4b8e4"
      },
      "source": [
        "%tensorflow_version 1.10\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.10`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD3wXVa07QiF"
      },
      "source": [
        "### 更改路徑"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GqmY9Ix7PXc"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/museGan\") #更改路徑\n",
        "dir='/content/drive/MyDrive/museGan'\n",
        "#os.getcwd() #查看當前路徑"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xDEfsqo4hop",
        "outputId": "ea900a52-4a7c-49c1-b475-2377a9e5283d"
      },
      "source": [
        "\"\"\"This script performs inference from a trained model.\"\"\"\n",
        "\n",
        "import logging\n",
        "import argparse\n",
        "from pprint import pformat\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import tensorflow as tf\n",
        "from config import LOGLEVEL, LOG_FORMAT\n",
        "from data_predict_version import load_data, get_samples\n",
        "from model import Model\n",
        "from utils import make_sure_path_exists, load_yaml, update_not_none\n",
        "LOGGER = logging.getLogger(\"musegan.inference\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2899968/45929032 bytes (6.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6053888/45929032 bytes (13.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b9191424/45929032 bytes (20.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b12394496/45929032 bytes (27.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b15417344/45929032 bytes (33.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b18489344/45929032 bytes (40.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b21495808/45929032 bytes (46.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24510464/45929032 bytes (53.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b27754496/45929032 bytes (60.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b30859264/45929032 bytes (67.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b33693696/45929032 bytes (73.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b36470784/45929032 bytes (79.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b38756352/45929032 bytes (84.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41279488/45929032 bytes (89.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b44425216/45929032 bytes (96.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUMCnSjU55Q4"
      },
      "source": [
        "def parse_arguments():\n",
        "\n",
        "    #設定以哪個資料夾下的Model做預測\n",
        "    predict_folder='exp/accompaniment/piano/'\n",
        "\n",
        "    \"\"\"Parse and return the command line arguments.\"\"\"\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--result_dir',default=predict_folder,\n",
        "                        help=\"Directory where the results are saved.\")\n",
        "    parser.add_argument('--checkpoint_dir',default=predict_folder+'model/',\n",
        "                        help=\"Directory that contains checkpoints.\")\n",
        "    parser.add_argument('--params', '--params_file', '--params_file_path', default=predict_folder+'params.yaml',\n",
        "                        help=\"Path to the file that defines the \"\n",
        "                             \"hyperparameters.\")\n",
        "    parser.add_argument('--config',default=predict_folder+'config.yaml', help=\"Path to the configuration file.\")\n",
        "    parser.add_argument('--runs', type=int, default=\"1\",\n",
        "                        help=\"Times to run the inference process.\")\n",
        "    parser.add_argument('--rows', type=int, default=5,\n",
        "                        help=\"Number of images per row to be generated.\")\n",
        "    parser.add_argument('--columns', type=int, default=5,\n",
        "                        help=\"Number of images per column to be generated.\")\n",
        "    parser.add_argument('--lower', type=float, default=-2,\n",
        "                        help=\"Lower bound of the truncated normal random \"\n",
        "                             \"variables.\")\n",
        "    parser.add_argument('--upper', type=float, default=2,\n",
        "                        help=\"Upper bound of the truncated normal random \"\n",
        "                             \"variables.\")\n",
        "    parser.add_argument('--gpu', '--gpu_device_num', type=str, default=\"0\",\n",
        "                        help=\"The GPU device number to use.\")\n",
        "    #args = parser.parse_args()\n",
        "    # colab改成沒有輸入params，等等用指定的方式指定args\n",
        "    args = parser.parse_args(args=[])\n",
        "    return args"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxilHSwq57yo"
      },
      "source": [
        "def setup():\n",
        "    \"\"\"Parse command line arguments, load model parameters, load configurations\n",
        "    and setup environment.\"\"\"\n",
        "    # Parse the command line arguments\n",
        "    args = parse_arguments()\n",
        "\n",
        "    # Load parameters\n",
        "    # colab改成沒有輸入params，等等用指定的方式指定args\n",
        "    params = load_yaml(args.params)\n",
        "\n",
        "    # Load training configurations\n",
        "    config = load_yaml(args.config)\n",
        "    update_not_none(config, vars(args))\n",
        "\n",
        "    # Set unspecified schedule steps to default values\n",
        "    for target in (config['learning_rate_schedule'], config['slope_schedule']):\n",
        "        if target['start'] is None:\n",
        "            target['start'] = 0\n",
        "        if target['end'] is None:\n",
        "            target['end'] = config['steps']\n",
        "\n",
        "    # Make sure result directory exists\n",
        "    make_sure_path_exists(config['result_dir'])\n",
        "\n",
        "    # Setup GPUs\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = config['gpu']\n",
        "\n",
        "    return params, config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XKNwrOi5-Ao"
      },
      "source": [
        "def inference_main():\n",
        "    \"\"\"Main function.\"\"\"\n",
        "    # Setup\n",
        "    logging.basicConfig(level=LOGLEVEL, format=LOG_FORMAT)\n",
        "    params, config = setup()\n",
        "    LOGGER.info(\"Using parameters:\\n%s\", pformat(params))\n",
        "    LOGGER.info(\"Using configurations:\\n%s\", pformat(config))\n",
        "\n",
        "    # ============================== Placeholders ==============================\n",
        "    placeholder_x = tf.placeholder(\n",
        "        tf.float32, shape=([None] + params['data_shape']))\n",
        "    placeholder_z = tf.placeholder(\n",
        "        tf.float32, shape=(None, params['latent_dim']))\n",
        "    placeholder_c = tf.placeholder(\n",
        "        tf.float32, shape=([None] + params['data_shape'][:-1] + [1]))\n",
        "    placeholder_suffix = tf.placeholder(tf.string)\n",
        "\n",
        "    # ================================= Model ==================================\n",
        "    # Create sampler configurations\n",
        "    sampler_config = {\n",
        "        'result_dir': config['result_dir'],\n",
        "        'image_grid': (config['rows'], config['columns']),\n",
        "        'suffix': placeholder_suffix, 'midi': config['midi'],\n",
        "        'colormap': np.array(config['colormap']).T,\n",
        "        'collect_save_arrays_op': config['save_array_samples'],\n",
        "        'collect_save_images_op': config['save_image_samples'],\n",
        "        'collect_save_pianorolls_op': config['save_pianoroll_samples']}\n",
        "\n",
        "    # Build model\n",
        "    model = Model(params)\n",
        "    if params.get('is_accompaniment'):\n",
        "        _ = model(\n",
        "            x=placeholder_x, c=placeholder_c, z=placeholder_z, mode='train',\n",
        "            params=params, config=config)\n",
        "        predict_nodes = model(\n",
        "            c=placeholder_c, z=placeholder_z, mode='predict', params=params,\n",
        "            config=sampler_config)\n",
        "    else:\n",
        "        _ = model(\n",
        "            x=placeholder_x, z=placeholder_z, mode='train', params=params,\n",
        "            config=config)\n",
        "        predict_nodes = model(\n",
        "            z=placeholder_z, mode='predict', params=params,\n",
        "            config=sampler_config)\n",
        "\n",
        "    # Get sampler op\n",
        "    sampler_op = tf.group([\n",
        "        predict_nodes[key] for key in (\n",
        "            'save_arrays_op', 'save_images_op', 'save_pianorolls_op')\n",
        "        if key in predict_nodes])\n",
        "\n",
        "    # ================================== Data ==================================\n",
        "    if params.get('is_accompaniment'):\n",
        "        data = load_data(config['data_source'], config['data_filename'])\n",
        "        print('predicted_data_issssss: ',data.shape)\n",
        "\n",
        "    # ========================== Session Preparation ===========================\n",
        "    # Get tensorflow session config\n",
        "    tf_config = tf.ConfigProto()\n",
        "    tf_config.gpu_options.allow_growth = True\n",
        "\n",
        "    # Create saver to restore variables\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    # =========================== Tensorflow Session ===========================\n",
        "    with tf.Session(config=tf_config) as sess:\n",
        "\n",
        "        # Restore the latest checkpoint\n",
        "        LOGGER.info(\"Restoring the latest checkpoint.\")\n",
        "        with open(os.path.join(config['checkpoint_dir'], 'checkpoint')) as f:\n",
        "            checkpoint_name = os.path.basename(\n",
        "                f.readline().split()[1].strip('\"'))\n",
        "        checkpoint_path = os.path.realpath(\n",
        "            os.path.join(config['checkpoint_dir'], checkpoint_name))\n",
        "        print('checkpoint_path is:::::',checkpoint_path)\n",
        "        saver.restore(sess, checkpoint_path)\n",
        "\n",
        "        # Run sampler op\n",
        "        for i in range(config['runs']):\n",
        "            feed_dict_sampler = {\n",
        "                placeholder_z: scipy.stats.truncnorm.rvs(\n",
        "                    config['lower'], config['upper'], size=(\n",
        "                        (config['rows'] * config['columns']),\n",
        "                        params['latent_dim'])),\n",
        "                placeholder_suffix: str(i)}  \n",
        "            if params.get('is_accompaniment'):\n",
        "                # sample_x = get_samples(\n",
        "                #     (config['rows'] * config['columns']), data,\n",
        "                #     use_random_transpose=config['use_random_transpose'])\n",
        "                # feed_dict_sampler[placeholder_c] = np.expand_dims(\n",
        "                #     sample_x[..., params['condition_track_idx']], -1)\n",
        "                feed_dict_sampler[placeholder_c]=data\n",
        "                # code in \"if(i<1)\" all are added py paul\n",
        "                if(i<1):\n",
        "                    tmp = feed_dict_sampler[placeholder_c]\n",
        "                    print(i,tmp.shape)\n",
        "                    for j in range(24):  \n",
        "                        print(feed_dict_sampler[placeholder_c].shape)  \n",
        "                        feed_dict_sampler[placeholder_c]=np.vstack([feed_dict_sampler[placeholder_c],tmp])                 \n",
        "                    \t\n",
        "                    #print('before:\\n',sample_x.shape,'\\nAfter:\\n', sample_x[..., params['condition_track_idx']].shape)\n",
        "                    #print('params[\\'condition_track_idx\\']:',params['condition_track_idx'])\n",
        "                    print('feed_dict_sampler:\\n',feed_dict_sampler[placeholder_c].shape)\n",
        "            sess.run(sampler_op, feed_dict=feed_dict_sampler)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7xl9ko8Sh6D"
      },
      "source": [
        "from pypianoroll import Multitrack\n",
        "base='/content/drive/MyDrive/museGan/exp/accompaniment/piano/pianorolls/fake_x_bernoulli_sampling/'\n",
        "def get_midi():\n",
        "  midi_file = Multitrack(base+'fake_x_bernoulli_sampling_0.npz')\n",
        "  midi_file.write(base+'fake_x_0.mid')\n",
        "  return midi_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I11r6ouGVUwJ",
        "outputId": "598716b4-b580-4f1b-f74a-df1dd9981d89"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOD0zA8RXMDX"
      },
      "source": [
        "# API 拿midi檔\n",
        "### flask & ngrok source : https://aishuafei.com/google-colab-flask/\n",
        "### midi:https://stackoverflow.com/questions/28121776/how-do-i-allow-users-to-download-a-midi-file-with-flask-without-getting-a-0-byte\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDyzwYDtTgXS",
        "outputId": "445dee5f-4d6e-4ace-b37a-5f79c1b84b6f"
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask,send_file\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "  midi = get_midi()\n",
        "  new_file = open(base+'fake_x_0.mid', 'rb')\n",
        "  return send_file(new_file, mimetype='audio/midi')\n",
        "  \n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
            "werkzeug             INFO      * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://ad7fc5cfcc34.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [15/Aug/2021 13:18:31] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "werkzeug             INFO     127.0.0.1 - - [15/Aug/2021 13:18:31] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [15/Aug/2021 13:19:09] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "werkzeug             INFO     127.0.0.1 - - [15/Aug/2021 13:19:09] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [15/Aug/2021 13:20:39] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "werkzeug             INFO     127.0.0.1 - - [15/Aug/2021 13:20:39] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [15/Aug/2021 13:20:43] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "werkzeug             INFO     127.0.0.1 - - [15/Aug/2021 13:20:43] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [15/Aug/2021 13:20:49] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "werkzeug             INFO     127.0.0.1 - - [15/Aug/2021 13:20:49] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [15/Aug/2021 13:21:19] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "werkzeug             INFO     127.0.0.1 - - [15/Aug/2021 13:21:19] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [15/Aug/2021 13:29:53] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "werkzeug             INFO     127.0.0.1 - - [15/Aug/2021 13:29:53] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [15/Aug/2021 13:29:54] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "werkzeug             INFO     127.0.0.1 - - [15/Aug/2021 13:29:54] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94iiC4643DSv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgdyVxFh6C73",
        "outputId": "dbb9297f-67d0-45ef-80dc-e9973696851d"
      },
      "source": [
        "inference_main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "musegan.inference    INFO     Using parameters:\n",
            "{'beat_resolution': 12,\n",
            " 'condition_track_idx': 1,\n",
            " 'data_shape': [4, 48, 84, 5],\n",
            " 'is_accompaniment': True,\n",
            " 'is_conditional': True,\n",
            " 'latent_dim': 128,\n",
            " 'nets': {'discriminator': 'default', 'generator': 'accompaniment'},\n",
            " 'use_binary_neurons': False}\n",
            "musegan.inference    INFO     Using configurations:\n",
            "{'adam': {'beta1': 0.5, 'beta2': 0.9},\n",
            " 'batch_size': 64,\n",
            " 'checkpoint_dir': 'exp/accompaniment/piano/model/',\n",
            " 'colormap': [[1.0, 0.0, 0.0],\n",
            "              [1.0, 0.5, 0.0],\n",
            "              [0.0, 1.0, 0.0],\n",
            "              [0.0, 0.0, 1.0],\n",
            "              [0.0, 0.5, 1.0]],\n",
            " 'columns': 5,\n",
            " 'config': 'exp/accompaniment/piano/config.yaml',\n",
            " 'data_filename': 'predict_input_data',\n",
            " 'data_root': './',\n",
            " 'data_source': 'npy',\n",
            " 'evaluate_steps': 100,\n",
            " 'gan_loss_type': 'wasserstein',\n",
            " 'gpu': '0',\n",
            " 'initial_learning_rate': 0.001,\n",
            " 'learning_rate_schedule': {'end': 50000, 'end_value': 0.0, 'start': 45000},\n",
            " 'log_loss_steps': 100,\n",
            " 'lower': -2,\n",
            " 'midi': {'is_drums': [1, 0, 0, 0, 0],\n",
            "          'lowest_pitch': 24,\n",
            "          'programs': [0, 0, 25, 33, 48],\n",
            "          'tempo': 100},\n",
            " 'n_dis_updates_per_gen_update': 5,\n",
            " 'n_jobs': 20,\n",
            " 'params': 'exp/accompaniment/piano/params.yaml',\n",
            " 'result_dir': 'exp/accompaniment/piano/',\n",
            " 'rows': 5,\n",
            " 'runs': 1,\n",
            " 'sample_grid': [8, 8],\n",
            " 'save_array_samples': True,\n",
            " 'save_checkpoint_steps': 10000,\n",
            " 'save_image_samples': True,\n",
            " 'save_pianoroll_samples': True,\n",
            " 'save_samples_steps': 100,\n",
            " 'save_summaries_steps': 0,\n",
            " 'slope_schedule': {'end': 50000, 'end_value': 5.0, 'start': 10000},\n",
            " 'steps': 50000,\n",
            " 'upper': 2,\n",
            " 'use_gradient_penalties': True,\n",
            " 'use_learning_rate_decay': True,\n",
            " 'use_random_transpose': False,\n",
            " 'use_slope_annealing': False,\n",
            " 'use_train_test_split': False}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/model.py:30: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/model.py:30: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/model.py:30: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/model.py:30: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "model                INFO     Building model.\n",
            "model                INFO     Building training nodes.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/model.py:77: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/model.py:77: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/model.py:78: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/model.py:78: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/presets/ops.py:12: conv3d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv3D` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/presets/ops.py:12: conv3d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv3D` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/convolutional.py:632: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/convolutional.py:632: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/presets/ops.py:21: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/presets/ops.py:21: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/presets/ops.py:16: conv3d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv3DTranspose` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/presets/ops.py:16: conv3d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv3DTranspose` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/presets/ops.py:8: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/presets/ops.py:8: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "model                INFO     Building losses.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/model.py:130: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/model.py:130: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "model                INFO     Building training ops.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/model.py:22: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/model.py:22: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/model.py:157: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/model.py:157: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/model.py:158: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/model.py:158: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/model.py:159: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/model.py:159: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/model.py:162: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/model.py:162: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/model.py:174: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/model.py:174: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/model.py:177: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/model.py:177: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/model.py:178: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/model.py:178: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "model                INFO     Building summaries.\n",
            "model                INFO     Building prediction nodes.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/model.py:261: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/model.py:261: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1025, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 869, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 608, in format\n",
            "    record.message = record.getMessage()\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 369, in getMessage\n",
            "    msg = msg % self.args\n",
            "TypeError: not all arguments converted during string formatting\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 845, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 532, in <lambda>\n",
            "    self.io_loop.add_callback(lambda: self._handle_events(self.socket, 0))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 448, in _handle_events\n",
            "    self._handle_recv()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 477, in _handle_recv\n",
            "    self._run_callback(callback, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n",
            "    callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
            "    return self.dispatch_shell(stream, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
            "    handler(stream, idents, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
            "    user_expressions, allow_stdin)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-12-c6c878ca4043>\", line 1, in <module>\n",
            "    inference_main()\n",
            "  File \"<ipython-input-8-f7403eecb778>\", line 54, in inference_main\n",
            "    data = load_data(config['data_source'], config['data_filename'])\n",
            "  File \"/content/drive/MyDrive/museGan/data_predict_version.py\", line 34, in load_data\n",
            "    LOGGER.info('root is : ',os.getcwd())\n",
            "Message: 'root is : '\n",
            "Arguments: ('/content/drive/MyDrive/museGan',)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "filename: filename\n",
            "root is :  /content/drive/MyDrive/museGan\n",
            "/content/drive/MyDrive/museGan\n",
            "predicted_data_issssss:  (1, 4, 48, 84, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "musegan.inference    INFO     Restoring the latest checkpoint.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "checkpoint_path is::::: /content/drive/My Drive/museGan/exp/accompaniment/piano/model/model.ckpt-300450\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/museGan/exp/accompaniment/piano/model/model.ckpt-300450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow           INFO     Restoring parameters from /content/drive/My Drive/museGan/exp/accompaniment/piano/model/model.ckpt-300450\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 (1, 4, 48, 84, 1)\n",
            "(1, 4, 48, 84, 1)\n",
            "(2, 4, 48, 84, 1)\n",
            "(3, 4, 48, 84, 1)\n",
            "(4, 4, 48, 84, 1)\n",
            "(5, 4, 48, 84, 1)\n",
            "(6, 4, 48, 84, 1)\n",
            "(7, 4, 48, 84, 1)\n",
            "(8, 4, 48, 84, 1)\n",
            "(9, 4, 48, 84, 1)\n",
            "(10, 4, 48, 84, 1)\n",
            "(11, 4, 48, 84, 1)\n",
            "(12, 4, 48, 84, 1)\n",
            "(13, 4, 48, 84, 1)\n",
            "(14, 4, 48, 84, 1)\n",
            "(15, 4, 48, 84, 1)\n",
            "(16, 4, 48, 84, 1)\n",
            "(17, 4, 48, 84, 1)\n",
            "(18, 4, 48, 84, 1)\n",
            "(19, 4, 48, 84, 1)\n",
            "(20, 4, 48, 84, 1)\n",
            "(21, 4, 48, 84, 1)\n",
            "(22, 4, 48, 84, 1)\n",
            "(23, 4, 48, 84, 1)\n",
            "(24, 4, 48, 84, 1)\n",
            "feed_dict_sampler:\n",
            " (25, 4, 48, 84, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}