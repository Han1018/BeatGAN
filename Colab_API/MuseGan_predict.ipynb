{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MuseGan_predict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMagjjrrRQvl0777ACfaMYP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Han1018/BeatGAN/blob/main/Colab_API/MuseGan_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn093Wwj6bi7"
      },
      "source": [
        "### 導入雲端硬碟"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Twq9ReH06bJC",
        "outputId": "26054c22-dedf-439a-d4bb-11c05fb07993"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yCyy19h6keA"
      },
      "source": [
        "### 下載必備套件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YCyssHc6hiQ",
        "outputId": "323758bb-34f8-4d92-ac23-152c0742bab8"
      },
      "source": [
        "!pip install pypianoroll==0.4.6\n",
        "!pip install tf-nightly\n",
        "!pip install gast==0.2.0\n",
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypianoroll==0.4.6\n",
            "  Downloading pypianoroll-0.4.6.tar.gz (18 kB)\n",
            "Requirement already satisfied: six<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll==0.4.6) (1.19.5)\n",
            "Requirement already satisfied: scipy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll==0.4.6) (1.4.1)\n",
            "Collecting pretty_midi<1.0,>=0.2.8\n",
            "  Downloading pretty_midi-0.2.9.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 6.2 MB/s \n",
            "\u001b[?25hCollecting mido>=1.1.16\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 8.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pypianoroll, pretty-midi\n",
            "  Building wheel for pypianoroll (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypianoroll: filename=pypianoroll-0.4.6-py3-none-any.whl size=20977 sha256=6e243020139e8231b58590775e9dbce6073d3edc861a2d904e9e753da8f2e8f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/ec/3b/4768365c13867b24acf342ae0b91d782b448e2d78039bbde0d\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-py3-none-any.whl size=5591953 sha256=37b451de3c5e34f337d49846a702bd4ec04110ecdca51654fba0839553984ddc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/74/7c/a06473ca8dcb63efb98c1e67667ce39d52100f837835ea18fa\n",
            "Successfully built pypianoroll pretty-midi\n",
            "Installing collected packages: mido, pretty-midi, pypianoroll\n",
            "Successfully installed mido-1.2.10 pretty-midi-0.2.9 pypianoroll-0.4.6\n",
            "Collecting tf-nightly\n",
            "  Downloading tf_nightly-2.7.0.dev20210922-cp37-cp37m-manylinux2010_x86_64.whl (489.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 489.2 MB 17 kB/s \n",
            "\u001b[?25hCollecting libclang~=11.1.0\n",
            "  Downloading libclang-11.1.0-py2.py3-none-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 49.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.12.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.37.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.17.3)\n",
            "Collecting keras-nightly~=2.7.0.dev\n",
            "  Downloading keras_nightly-2.7.0.dev2021092207-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 37.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12.1)\n",
            "Collecting tb-nightly~=2.7.0.a\n",
            "  Downloading tb_nightly-2.7.0a20210921-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 51.1 MB/s \n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.20.0\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.21.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.40.0)\n",
            "Collecting tf-estimator-nightly~=2.7.0.dev\n",
            "  Downloading tf_estimator_nightly-2.7.0.dev2021092208-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 69.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.19.5)\n",
            "Collecting flatbuffers~=2.0\n",
            "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tf-nightly) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.7.0.a->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.7.0.a->tf-nightly) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.7.0.a->tf-nightly) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.7.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.7.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.7.0.a->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.7.0.a->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly~=2.7.0.a->tf-nightly) (3.5.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow-io-gcs-filesystem, tb-nightly, libclang, keras-nightly, flatbuffers, tf-nightly\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires flatbuffers~=1.12.0, but you have flatbuffers 2.0 which is incompatible.\u001b[0m\n",
            "Successfully installed flatbuffers-2.0 keras-nightly-2.7.0.dev2021092207 libclang-11.1.0 tb-nightly-2.7.0a20210921 tensorflow-io-gcs-filesystem-0.21.0 tf-estimator-nightly-2.7.0.dev2021092208 tf-nightly-2.7.0.dev20210922\n",
            "Collecting gast==0.2.0\n",
            "  Downloading gast-0.2.0.tar.gz (9.4 kB)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.0-py3-none-any.whl size=6664 sha256=af97cfbf19acadd624aef7faac331013e717b6cd51b5b44695299063ff08129f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/5c/7c/fa61262218d07604f2d0cf2021093ca599fa7d2df22ff27bb7\n",
            "Successfully built gast\n",
            "Installing collected packages: gast\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-nightly 2.7.0.dev20210922 requires gast==0.4.0, but you have gast 0.2.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires flatbuffers~=1.12.0, but you have flatbuffers 2.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires gast==0.4.0, but you have gast 0.2.0 which is incompatible.\n",
            "tensorflow-probability 0.13.0 requires gast>=0.3.2, but you have gast 0.2.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.0\n",
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONCSUMnN6qzO"
      },
      "source": [
        "### 載入一代tf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i8Ag9kM6of9",
        "outputId": "795348f7-72ec-40c7-cb24-378e49732724"
      },
      "source": [
        "%tensorflow_version 1.10\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.10`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD3wXVa07QiF"
      },
      "source": [
        "### 更改路徑"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GqmY9Ix7PXc"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/museGan\") #更改路徑\n",
        "dir='/content/drive/MyDrive/museGan'\n",
        "#os.getcwd() #查看當前路徑"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xDEfsqo4hop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "258caa2d-f8b9-48c9-bd76-5095df0a2d81"
      },
      "source": [
        "\"\"\"This script performs inference from a trained model.\"\"\"\n",
        "\n",
        "import logging\n",
        "import argparse\n",
        "from pprint import pformat\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import tensorflow as tf\n",
        "from config import LOGLEVEL, LOG_FORMAT\n",
        "from data_predict_version import load_data, get_samples\n",
        "from model import Model\n",
        "from utils import make_sure_path_exists, load_yaml, update_not_none\n",
        "LOGGER = logging.getLogger(\"musegan.inference\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3268608/45929032 bytes (7.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b7184384/45929032 bytes (15.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11132928/45929032 bytes (24.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b14991360/45929032 bytes (32.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b18399232/45929032 bytes (40.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b22192128/45929032 bytes (48.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b26017792/45929032 bytes (56.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b29925376/45929032 bytes (65.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b33980416/45929032 bytes (74.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b37994496/45929032 bytes (82.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41779200/45929032 bytes (91.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45883392/45929032 bytes (99.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUMCnSjU55Q4"
      },
      "source": [
        "def parse_arguments(folderName):\n",
        "\n",
        "    #設定以哪個資料夾下的Model做預測\n",
        "    # predict_folder='exp/default_2/'\n",
        "    predict_folder = folderName\n",
        "\n",
        "    \"\"\"Parse and return the command line arguments.\"\"\"\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--result_dir',default=predict_folder,\n",
        "                        help=\"Directory where the results are saved.\")\n",
        "    parser.add_argument('--checkpoint_dir',default=predict_folder+'model/',\n",
        "                        help=\"Directory that contains checkpoints.\")\n",
        "    parser.add_argument('--params', '--params_file', '--params_file_path', default=predict_folder+'params.yaml',\n",
        "                        help=\"Path to the file that defines the \"\n",
        "                             \"hyperparameters.\")\n",
        "    parser.add_argument('--config',default=predict_folder+'config.yaml', help=\"Path to the configuration file.\")\n",
        "    parser.add_argument('--runs', type=int, default=\"1\",\n",
        "                        help=\"Times to run the inference process.\")\n",
        "    parser.add_argument('--rows', type=int, default=5,\n",
        "                        help=\"Number of images per row to be generated.\")\n",
        "    parser.add_argument('--columns', type=int, default=5,\n",
        "                        help=\"Number of images per column to be generated.\")\n",
        "    parser.add_argument('--lower', type=float, default=-2,\n",
        "                        help=\"Lower bound of the truncated normal random \"\n",
        "                             \"variables.\")\n",
        "    parser.add_argument('--upper', type=float, default=2,\n",
        "                        help=\"Upper bound of the truncated normal random \"\n",
        "                             \"variables.\")\n",
        "    parser.add_argument('--gpu', '--gpu_device_num', type=str, default=\"0\",\n",
        "                        help=\"The GPU device number to use.\")\n",
        "    #args = parser.parse_args()\n",
        "    # colab改成沒有輸入params，等等用指定的方式指定args\n",
        "    args = parser.parse_args(args=[])\n",
        "    return args"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxilHSwq57yo"
      },
      "source": [
        "def setup(folderName):\n",
        "    \"\"\"Parse command line arguments, load model parameters, load configurations\n",
        "    and setup environment.\"\"\"\n",
        "    # Parse the command line arguments\n",
        "    args = parse_arguments(folderName)\n",
        "\n",
        "    # Load parameters\n",
        "    # colab改成沒有輸入params，等等用指定的方式指定args\n",
        "    params = load_yaml(args.params)\n",
        "\n",
        "    # Load training configurations\n",
        "    config = load_yaml(args.config)\n",
        "    update_not_none(config, vars(args))\n",
        "\n",
        "    # Set unspecified schedule steps to default values\n",
        "    for target in (config['learning_rate_schedule'], config['slope_schedule']):\n",
        "        if target['start'] is None:\n",
        "            target['start'] = 0\n",
        "        if target['end'] is None:\n",
        "            target['end'] = config['steps']\n",
        "\n",
        "    # Make sure result directory exists\n",
        "    make_sure_path_exists(config['result_dir'])\n",
        "\n",
        "    # Setup GPUs\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = config['gpu']\n",
        "\n",
        "    return params, config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XKNwrOi5-Ao"
      },
      "source": [
        "def inference_main(folderName):\n",
        "    \"\"\"Main function.\"\"\"\n",
        "    # Setup\n",
        "    logging.basicConfig(level=LOGLEVEL, format=LOG_FORMAT)\n",
        "    params, config = setup(folderName)\n",
        "    LOGGER.info(\"Using parameters:\\n%s\", pformat(params))\n",
        "    LOGGER.info(\"Using configurations:\\n%s\", pformat(config))\n",
        "\n",
        "    # ============================== Placeholders ==============================\n",
        "    placeholder_x = tf.placeholder(\n",
        "        tf.float32, shape=([None] + params['data_shape']))\n",
        "    placeholder_z = tf.placeholder(\n",
        "        tf.float32, shape=(None, params['latent_dim']))\n",
        "    placeholder_c = tf.placeholder(\n",
        "        tf.float32, shape=([None] + params['data_shape'][:-1] + [1]))\n",
        "    placeholder_suffix = tf.placeholder(tf.string)\n",
        "\n",
        "    # ================================= Model ==================================\n",
        "    # Create sampler configurations\n",
        "    sampler_config = {\n",
        "        'result_dir': config['result_dir'],\n",
        "        'image_grid': (config['rows'], config['columns']),\n",
        "        'suffix': placeholder_suffix, 'midi': config['midi'],\n",
        "        'colormap': np.array(config['colormap']).T,\n",
        "        'collect_save_arrays_op': config['save_array_samples'],\n",
        "        'collect_save_images_op': config['save_image_samples'],\n",
        "        'collect_save_pianorolls_op': config['save_pianoroll_samples']}\n",
        "\n",
        "    # Build model\n",
        "    model = Model(params)\n",
        "    if params.get('is_accompaniment'):\n",
        "        _ = model(\n",
        "            x=placeholder_x, c=placeholder_c, z=placeholder_z, mode='train',\n",
        "            params=params, config=config)\n",
        "        predict_nodes = model(\n",
        "            c=placeholder_c, z=placeholder_z, mode='predict', params=params,\n",
        "            config=sampler_config)\n",
        "    else:\n",
        "        _ = model(\n",
        "            x=placeholder_x, z=placeholder_z, mode='train', params=params,\n",
        "            config=config)\n",
        "        predict_nodes = model(\n",
        "            z=placeholder_z, mode='predict', params=params,\n",
        "            config=sampler_config)\n",
        "\n",
        "    # Get sampler op\n",
        "    sampler_op = tf.group([\n",
        "        predict_nodes[key] for key in (\n",
        "            'save_arrays_op', 'save_images_op', 'save_pianorolls_op')\n",
        "        if key in predict_nodes])\n",
        "\n",
        "    # ================================== Data ==================================\n",
        "    if params.get('is_accompaniment'):\n",
        "        data = load_data(config['data_source'], config['data_filename'])\n",
        "        print('predicted_data_issssss: ',data.shape)\n",
        "\n",
        "    # ========================== Session Preparation ===========================\n",
        "    # Get tensorflow session config\n",
        "    tf_config = tf.ConfigProto()\n",
        "    tf_config.gpu_options.allow_growth = True\n",
        "\n",
        "    # Create saver to restore variables\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    # =========================== Tensorflow Session ===========================\n",
        "    with tf.Session(config=tf_config) as sess:\n",
        "\n",
        "        # Restore the latest checkpoint\n",
        "        LOGGER.info(\"Restoring the latest checkpoint.\")\n",
        "        with open(os.path.join(config['checkpoint_dir'], 'checkpoint')) as f:\n",
        "            checkpoint_name = os.path.basename(\n",
        "                f.readline().split()[1].strip('\"'))\n",
        "        checkpoint_path = os.path.realpath(\n",
        "            os.path.join(config['checkpoint_dir'], checkpoint_name))\n",
        "        print('checkpoint_path is:::::',checkpoint_path)\n",
        "        saver.restore(sess, checkpoint_path)\n",
        "\n",
        "        # Run sampler op\n",
        "        for i in range(config['runs']):\n",
        "            feed_dict_sampler = {\n",
        "                placeholder_z: scipy.stats.truncnorm.rvs(\n",
        "                    config['lower'], config['upper'], size=(\n",
        "                        (config['rows'] * config['columns']),\n",
        "                        params['latent_dim'])),\n",
        "                placeholder_suffix: str(i)}  \n",
        "            if params.get('is_accompaniment'):\n",
        "                # sample_x = get_samples(\n",
        "                #     (config['rows'] * config['columns']), data,\n",
        "                #     use_random_transpose=config['use_random_transpose'])\n",
        "                # feed_dict_sampler[placeholder_c] = np.expand_dims(\n",
        "                #     sample_x[..., params['condition_track_idx']], -1)\n",
        "                feed_dict_sampler[placeholder_c]=data\n",
        "                # code in \"if(i<1)\" all are added py paul\n",
        "                if(i<1):\n",
        "                    tmp = feed_dict_sampler[placeholder_c]\n",
        "                    print(i,tmp.shape)\n",
        "                    for j in range(24):  \n",
        "                        print(feed_dict_sampler[placeholder_c].shape)  \n",
        "                        feed_dict_sampler[placeholder_c]=np.vstack([feed_dict_sampler[placeholder_c],tmp])                 \n",
        "                    \t\n",
        "                    #print('before:\\n',sample_x.shape,'\\nAfter:\\n', sample_x[..., params['condition_track_idx']].shape)\n",
        "                    #print('params[\\'condition_track_idx\\']:',params['condition_track_idx'])\n",
        "                    print('feed_dict_sampler:\\n',feed_dict_sampler[placeholder_c].shape)\n",
        "            sess.run(sampler_op, feed_dict=feed_dict_sampler)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7xl9ko8Sh6D"
      },
      "source": [
        "from pypianoroll import Multitrack\n",
        "\n",
        "def get_midi(route):\n",
        "  midi_file = Multitrack(route+'fake_x_bernoulli_sampling_0.npz')\n",
        "  midi_file.write(route+'fake_x_0.mid')\n",
        "  return midi_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I11r6ouGVUwJ"
      },
      "source": [
        "\n",
        "def predict_trackCondition():\n",
        "  folderName = 'exp/accompaniment/piano/'\n",
        "  inference_main(folderName)\n",
        "\n",
        "def predict_Normal(genre):\n",
        "\n",
        "  folderName = 'exp/'+genre+'/'\n",
        "  inference_main(folderName)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFCwxCkdmhGh"
      },
      "source": [
        "def get_genre(genre):\n",
        "  if(genre is 0):\n",
        "    return 'normal_pop'\n",
        "  if(genre is 1):\n",
        "    return 'default_2'\n",
        "  if(genre is 2):\n",
        "    return 'normal_electronic'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOD0zA8RXMDX"
      },
      "source": [
        "# API 拿midi檔\n",
        "### flask & ngrok source : https://aishuafei.com/google-colab-flask/\n",
        "### midi:https://stackoverflow.com/questions/28121776/how-do-i-allow-users-to-download-a-midi-file-with-flask-without-getting-a-0-byte\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDyzwYDtTgXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f6d5787-8fdc-4432-bfc5-31e24e9eab41"
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask,send_file,request\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "\n",
        "@app.route(\"/trackCondition\")\n",
        "def trackCondition():\n",
        "  base='/content/drive/MyDrive/museGan/exp/accompaniment/piano/pianorolls/fake_x_bernoulli_sampling/'\n",
        "  predict_trackCondition()\n",
        "  midi = get_midi(base)\n",
        "  new_file = open(base+'fake_x_0.mid', 'rb')\n",
        "  return send_file(new_file, mimetype='audio/midi')\n",
        "  \n",
        "@app.route(\"/random\")\n",
        "def ramdom():\n",
        "  # base param\n",
        "  base ='/content/drive/MyDrive/museGan/exp/'\n",
        "  lastParam = '/pianorolls/fake_x_bernoulli_sampling/'\n",
        "\n",
        "  #request data\n",
        "  rJson = request.json\n",
        "  genre_num = rJson['genre']#0,1,2\n",
        "  \n",
        "  genre = get_genre(genre_num)\n",
        "  \n",
        "  predict_Normal(genre)\n",
        "  midi = get_midi(base+genre+lastParam)\n",
        "  new_file = open(base+genre+lastParam+'fake_x_0.mid', 'rb')\n",
        "  return send_file(new_file, mimetype='audio/midi')\n",
        "  \n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Running on http://7bf8-34-125-27-11.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "musegan.inference    INFO     Using parameters:\n",
            "{'beat_resolution': 12,\n",
            " 'condition_track_idx': None,\n",
            " 'data_shape': [4, 48, 84, 5],\n",
            " 'is_accompaniment': False,\n",
            " 'is_conditional': False,\n",
            " 'latent_dim': 128,\n",
            " 'nets': {'discriminator': 'default', 'generator': 'default'},\n",
            " 'use_binary_neurons': False}\n",
            "musegan.inference    INFO     Using configurations:\n",
            "{'adam': {'beta1': 0.5, 'beta2': 0.9},\n",
            " 'batch_size': 64,\n",
            " 'checkpoint_dir': 'exp/normal_pop/model/',\n",
            " 'colormap': [[1.0, 0.0, 0.0],\n",
            "              [1.0, 0.5, 0.0],\n",
            "              [0.0, 1.0, 0.0],\n",
            "              [0.0, 0.0, 1.0],\n",
            "              [0.0, 0.5, 1.0]],\n",
            " 'columns': 5,\n",
            " 'config': 'exp/normal_pop/config.yaml',\n",
            " 'data_filename': 'train_x_lpd_5_phr',\n",
            " 'data_root': None,\n",
            " 'data_source': 'sa',\n",
            " 'evaluate_steps': 100,\n",
            " 'gan_loss_type': 'wasserstein',\n",
            " 'gpu': '0',\n",
            " 'initial_learning_rate': 0.001,\n",
            " 'learning_rate_schedule': {'end': 50000, 'end_value': 0.0, 'start': 45000},\n",
            " 'log_loss_steps': 100,\n",
            " 'lower': -2,\n",
            " 'midi': {'is_drums': [1, 0, 0, 0, 0],\n",
            "          'lowest_pitch': 24,\n",
            "          'programs': [0, 0, 25, 33, 48],\n",
            "          'tempo': 100},\n",
            " 'n_dis_updates_per_gen_update': 5,\n",
            " 'n_jobs': 20,\n",
            " 'params': 'exp/normal_pop/params.yaml',\n",
            " 'result_dir': 'exp/normal_pop/',\n",
            " 'rows': 5,\n",
            " 'runs': 1,\n",
            " 'sample_grid': [8, 8],\n",
            " 'save_array_samples': True,\n",
            " 'save_checkpoint_steps': 10000,\n",
            " 'save_image_samples': True,\n",
            " 'save_pianoroll_samples': True,\n",
            " 'save_samples_steps': 100,\n",
            " 'save_summaries_steps': 0,\n",
            " 'slope_schedule': {'end': 50000, 'end_value': 5.0, 'start': 10000},\n",
            " 'steps': 50000,\n",
            " 'upper': 2,\n",
            " 'use_gradient_penalties': True,\n",
            " 'use_learning_rate_decay': True,\n",
            " 'use_random_transpose': False,\n",
            " 'use_slope_annealing': False,\n",
            " 'use_train_test_split': False}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/museGan/model.py:30: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/My Drive/museGan/model.py:30: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/museGan/model.py:30: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/My Drive/museGan/model.py:30: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "model                INFO     Building model.\n",
            "model                INFO     Building training nodes.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/museGan/model.py:77: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/My Drive/museGan/model.py:77: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/museGan/model.py:78: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/My Drive/museGan/model.py:78: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/presets/ops.py:16: conv3d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv3DTranspose` instead.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/presets/ops.py:16: conv3d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv3DTranspose` instead.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/convolutional.py:1453: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/convolutional.py:1453: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/presets/ops.py:21: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/presets/ops.py:21: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/presets/ops.py:12: conv3d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv3D` instead.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/presets/ops.py:12: conv3d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv3D` instead.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/museGan/presets/ops.py:8: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/MyDrive/museGan/presets/ops.py:8: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "model                INFO     Building losses.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of true data:  (?, 4, 48, 84, 5)\n",
            "Shape of fake data:  (?, 4, 48, 84, 5)\n",
            "WARNING:tensorflow:From /content/drive/My Drive/museGan/model.py:136: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/My Drive/museGan/model.py:136: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "model                INFO     Building training ops.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/museGan/model.py:22: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/My Drive/museGan/model.py:22: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/museGan/model.py:163: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/My Drive/museGan/model.py:163: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/museGan/model.py:164: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/My Drive/museGan/model.py:164: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/museGan/model.py:165: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/My Drive/museGan/model.py:165: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/museGan/model.py:168: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/My Drive/museGan/model.py:168: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/museGan/model.py:180: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/My Drive/museGan/model.py:180: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/museGan/model.py:183: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/My Drive/museGan/model.py:183: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/museGan/model.py:184: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/My Drive/museGan/model.py:184: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "model                INFO     Building summaries.\n",
            "model                INFO     Building prediction nodes.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/museGan/model.py:267: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           WARNING  From /content/drive/My Drive/museGan/model.py:267: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "musegan.inference    INFO     Restoring the latest checkpoint.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint_path is::::: /content/drive/My Drive/museGan/exp/normal_pop/model/model.ckpt-240000\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/museGan/exp/normal_pop/model/model.ckpt-240000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           INFO     Restoring parameters from /content/drive/My Drive/museGan/exp/normal_pop/model/model.ckpt-240000\n",
            "127.0.0.1 - - [22/Sep/2021 09:31:16] \"\u001b[37mGET /random HTTP/1.1\u001b[0m\" 200 -\n",
            "werkzeug             INFO     127.0.0.1 - - [22/Sep/2021 09:31:16] \"\u001b[37mGET /random HTTP/1.1\u001b[0m\" 200 -\n",
            "musegan.inference    INFO     Using parameters:\n",
            "{'beat_resolution': 12,\n",
            " 'condition_track_idx': None,\n",
            " 'data_shape': [4, 48, 84, 5],\n",
            " 'is_accompaniment': False,\n",
            " 'is_conditional': False,\n",
            " 'latent_dim': 128,\n",
            " 'nets': {'discriminator': 'default', 'generator': 'default'},\n",
            " 'use_binary_neurons': False}\n",
            "musegan.inference    INFO     Using configurations:\n",
            "{'adam': {'beta1': 0.5, 'beta2': 0.9},\n",
            " 'batch_size': 64,\n",
            " 'checkpoint_dir': 'exp/default_2/model/',\n",
            " 'colormap': [[1.0, 0.0, 0.0],\n",
            "              [1.0, 0.5, 0.0],\n",
            "              [0.0, 1.0, 0.0],\n",
            "              [0.0, 0.0, 1.0],\n",
            "              [0.0, 0.5, 1.0]],\n",
            " 'columns': 5,\n",
            " 'config': 'exp/default_2/config.yaml',\n",
            " 'data_filename': 'train_x_lpd_5_phr',\n",
            " 'data_root': None,\n",
            " 'data_source': 'sa',\n",
            " 'evaluate_steps': 100,\n",
            " 'gan_loss_type': 'wasserstein',\n",
            " 'gpu': '0',\n",
            " 'initial_learning_rate': 0.001,\n",
            " 'learning_rate_schedule': {'end': 50000, 'end_value': 0.0, 'start': 45000},\n",
            " 'log_loss_steps': 100,\n",
            " 'lower': -2,\n",
            " 'midi': {'is_drums': [1, 0, 0, 0, 0],\n",
            "          'lowest_pitch': 24,\n",
            "          'programs': [0, 0, 25, 33, 48],\n",
            "          'tempo': 100},\n",
            " 'n_dis_updates_per_gen_update': 5,\n",
            " 'n_jobs': 20,\n",
            " 'params': 'exp/default_2/params.yaml',\n",
            " 'result_dir': 'exp/default_2/',\n",
            " 'rows': 5,\n",
            " 'runs': 1,\n",
            " 'sample_grid': [8, 8],\n",
            " 'save_array_samples': True,\n",
            " 'save_checkpoint_steps': 10000,\n",
            " 'save_image_samples': True,\n",
            " 'save_pianoroll_samples': True,\n",
            " 'save_samples_steps': 100,\n",
            " 'save_summaries_steps': 0,\n",
            " 'slope_schedule': {'end': 50000, 'end_value': 5.0, 'start': 10000},\n",
            " 'steps': 50000,\n",
            " 'upper': 2,\n",
            " 'use_gradient_penalties': True,\n",
            " 'use_learning_rate_decay': True,\n",
            " 'use_random_transpose': False,\n",
            " 'use_slope_annealing': False,\n",
            " 'use_train_test_split': False}\n",
            "model                INFO     Building model.\n",
            "model                INFO     Building training nodes.\n",
            "model                INFO     Building losses.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of true data:  (?, 4, 48, 84, 5)\n",
            "Shape of fake data:  (?, 4, 48, 84, 5)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model                INFO     Building training ops.\n",
            "model                INFO     Building summaries.\n",
            "model                INFO     Building prediction nodes.\n",
            "musegan.inference    INFO     Restoring the latest checkpoint.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint_path is::::: /content/drive/My Drive/museGan/exp/default_2/model/model.ckpt-180000\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/museGan/exp/default_2/model/model.ckpt-180000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           INFO     Restoring parameters from /content/drive/My Drive/museGan/exp/default_2/model/model.ckpt-180000\n",
            "127.0.0.1 - - [22/Sep/2021 10:18:25] \"\u001b[37mGET /random HTTP/1.1\u001b[0m\" 200 -\n",
            "werkzeug             INFO     127.0.0.1 - - [22/Sep/2021 10:18:25] \"\u001b[37mGET /random HTTP/1.1\u001b[0m\" 200 -\n",
            "musegan.inference    INFO     Using parameters:\n",
            "{'beat_resolution': 12,\n",
            " 'condition_track_idx': None,\n",
            " 'data_shape': [4, 48, 84, 5],\n",
            " 'is_accompaniment': False,\n",
            " 'is_conditional': False,\n",
            " 'latent_dim': 128,\n",
            " 'nets': {'discriminator': 'default', 'generator': 'default'},\n",
            " 'use_binary_neurons': False}\n",
            "musegan.inference    INFO     Using configurations:\n",
            "{'adam': {'beta1': 0.5, 'beta2': 0.9},\n",
            " 'batch_size': 64,\n",
            " 'checkpoint_dir': 'exp/normal_electronic/model/',\n",
            " 'colormap': [[1.0, 0.0, 0.0],\n",
            "              [1.0, 0.5, 0.0],\n",
            "              [0.0, 1.0, 0.0],\n",
            "              [0.0, 0.0, 1.0],\n",
            "              [0.0, 0.5, 1.0]],\n",
            " 'columns': 5,\n",
            " 'config': 'exp/normal_electronic/config.yaml',\n",
            " 'data_filename': 'train_x_lpd_5_phr',\n",
            " 'data_root': None,\n",
            " 'data_source': 'sa',\n",
            " 'evaluate_steps': 100,\n",
            " 'gan_loss_type': 'wasserstein',\n",
            " 'gpu': '0',\n",
            " 'initial_learning_rate': 0.001,\n",
            " 'learning_rate_schedule': {'end': 50000, 'end_value': 0.0, 'start': 45000},\n",
            " 'log_loss_steps': 100,\n",
            " 'lower': -2,\n",
            " 'midi': {'is_drums': [1, 0, 0, 0, 0],\n",
            "          'lowest_pitch': 24,\n",
            "          'programs': [0, 0, 25, 33, 48],\n",
            "          'tempo': 100},\n",
            " 'n_dis_updates_per_gen_update': 5,\n",
            " 'n_jobs': 20,\n",
            " 'params': 'exp/normal_electronic/params.yaml',\n",
            " 'result_dir': 'exp/normal_electronic/',\n",
            " 'rows': 5,\n",
            " 'runs': 1,\n",
            " 'sample_grid': [8, 8],\n",
            " 'save_array_samples': True,\n",
            " 'save_checkpoint_steps': 10000,\n",
            " 'save_image_samples': True,\n",
            " 'save_pianoroll_samples': True,\n",
            " 'save_samples_steps': 100,\n",
            " 'save_summaries_steps': 0,\n",
            " 'slope_schedule': {'end': 50000, 'end_value': 5.0, 'start': 10000},\n",
            " 'steps': 50000,\n",
            " 'upper': 2,\n",
            " 'use_gradient_penalties': True,\n",
            " 'use_learning_rate_decay': True,\n",
            " 'use_random_transpose': False,\n",
            " 'use_slope_annealing': False,\n",
            " 'use_train_test_split': False}\n",
            "model                INFO     Building model.\n",
            "model                INFO     Building training nodes.\n",
            "model                INFO     Building losses.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of true data:  (?, 4, 48, 84, 5)\n",
            "Shape of fake data:  (?, 4, 48, 84, 5)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model                INFO     Building training ops.\n",
            "model                INFO     Building summaries.\n",
            "model                INFO     Building prediction nodes.\n",
            "musegan.inference    INFO     Restoring the latest checkpoint.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint_path is::::: /content/drive/My Drive/museGan/exp/normal_electronic/model/model.ckpt-240000\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/museGan/exp/normal_electronic/model/model.ckpt-240000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           INFO     Restoring parameters from /content/drive/My Drive/museGan/exp/normal_electronic/model/model.ckpt-240000\n",
            "127.0.0.1 - - [22/Sep/2021 10:19:42] \"\u001b[37mGET /random HTTP/1.1\u001b[0m\" 200 -\n",
            "werkzeug             INFO     127.0.0.1 - - [22/Sep/2021 10:19:42] \"\u001b[37mGET /random HTTP/1.1\u001b[0m\" 200 -\n",
            "musegan.inference    INFO     Using parameters:\n",
            "{'beat_resolution': 12,\n",
            " 'condition_track_idx': None,\n",
            " 'data_shape': [4, 48, 84, 5],\n",
            " 'is_accompaniment': False,\n",
            " 'is_conditional': False,\n",
            " 'latent_dim': 128,\n",
            " 'nets': {'discriminator': 'default', 'generator': 'default'},\n",
            " 'use_binary_neurons': False}\n",
            "musegan.inference    INFO     Using configurations:\n",
            "{'adam': {'beta1': 0.5, 'beta2': 0.9},\n",
            " 'batch_size': 64,\n",
            " 'checkpoint_dir': 'exp/normal_pop/model/',\n",
            " 'colormap': [[1.0, 0.0, 0.0],\n",
            "              [1.0, 0.5, 0.0],\n",
            "              [0.0, 1.0, 0.0],\n",
            "              [0.0, 0.0, 1.0],\n",
            "              [0.0, 0.5, 1.0]],\n",
            " 'columns': 5,\n",
            " 'config': 'exp/normal_pop/config.yaml',\n",
            " 'data_filename': 'train_x_lpd_5_phr',\n",
            " 'data_root': None,\n",
            " 'data_source': 'sa',\n",
            " 'evaluate_steps': 100,\n",
            " 'gan_loss_type': 'wasserstein',\n",
            " 'gpu': '0',\n",
            " 'initial_learning_rate': 0.001,\n",
            " 'learning_rate_schedule': {'end': 50000, 'end_value': 0.0, 'start': 45000},\n",
            " 'log_loss_steps': 100,\n",
            " 'lower': -2,\n",
            " 'midi': {'is_drums': [1, 0, 0, 0, 0],\n",
            "          'lowest_pitch': 24,\n",
            "          'programs': [0, 0, 25, 33, 48],\n",
            "          'tempo': 100},\n",
            " 'n_dis_updates_per_gen_update': 5,\n",
            " 'n_jobs': 20,\n",
            " 'params': 'exp/normal_pop/params.yaml',\n",
            " 'result_dir': 'exp/normal_pop/',\n",
            " 'rows': 5,\n",
            " 'runs': 1,\n",
            " 'sample_grid': [8, 8],\n",
            " 'save_array_samples': True,\n",
            " 'save_checkpoint_steps': 10000,\n",
            " 'save_image_samples': True,\n",
            " 'save_pianoroll_samples': True,\n",
            " 'save_samples_steps': 100,\n",
            " 'save_summaries_steps': 0,\n",
            " 'slope_schedule': {'end': 50000, 'end_value': 5.0, 'start': 10000},\n",
            " 'steps': 50000,\n",
            " 'upper': 2,\n",
            " 'use_gradient_penalties': True,\n",
            " 'use_learning_rate_decay': True,\n",
            " 'use_random_transpose': False,\n",
            " 'use_slope_annealing': False,\n",
            " 'use_train_test_split': False}\n",
            "model                INFO     Building model.\n",
            "model                INFO     Building training nodes.\n",
            "model                INFO     Building losses.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of true data:  (?, 4, 48, 84, 5)\n",
            "Shape of fake data:  (?, 4, 48, 84, 5)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model                INFO     Building training ops.\n",
            "model                INFO     Building summaries.\n",
            "model                INFO     Building prediction nodes.\n",
            "musegan.inference    INFO     Restoring the latest checkpoint.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint_path is::::: /content/drive/My Drive/museGan/exp/normal_pop/model/model.ckpt-240000\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/museGan/exp/normal_pop/model/model.ckpt-240000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tensorflow           INFO     Restoring parameters from /content/drive/My Drive/museGan/exp/normal_pop/model/model.ckpt-240000\n",
            "127.0.0.1 - - [22/Sep/2021 10:21:00] \"\u001b[37mGET /random HTTP/1.1\u001b[0m\" 200 -\n",
            "werkzeug             INFO     127.0.0.1 - - [22/Sep/2021 10:21:00] \"\u001b[37mGET /random HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    }
  ]
}