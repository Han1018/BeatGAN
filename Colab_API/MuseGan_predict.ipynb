{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MuseGan_predict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOoIavQW9HQDtc5zhMXeLOl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Han1018/BeatGAN/blob/GenerateMidiAPI/Colab_API/MuseGan_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn093Wwj6bi7"
      },
      "source": [
        "### 導入雲端硬碟"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Twq9ReH06bJC",
        "outputId": "ab4ac7ec-b124-492c-85a0-d05e54e007d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yCyy19h6keA"
      },
      "source": [
        "### 下載必備套件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YCyssHc6hiQ",
        "outputId": "f6159767-15e8-48de-a1d4-f3e2a477d96c"
      },
      "source": [
        "!pip install pypianoroll==0.4.6\n",
        "!pip install tf-nightly\n",
        "!pip install gast==0.2.0\n",
        "!pip install flask-ngrok"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypianoroll==0.4.6 in /usr/local/lib/python3.7/dist-packages (0.4.6)\n",
            "Requirement already satisfied: pretty-midi<1.0,>=0.2.8 in /usr/local/lib/python3.7/dist-packages (from pypianoroll==0.4.6) (0.2.9)\n",
            "Requirement already satisfied: six<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: scipy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll==0.4.6) (1.4.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll==0.4.6) (1.19.5)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.7/dist-packages (from pretty-midi<1.0,>=0.2.8->pypianoroll==0.4.6) (1.2.10)\n",
            "Requirement already satisfied: tf-nightly in /usr/local/lib/python3.7/dist-packages (2.8.0.dev20211003)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.19.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n",
            "Collecting gast<0.5.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.21.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (12.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: keras-nightly~=2.7.0.dev in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (2.7.0.dev2021100207)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.12.0)\n",
            "Requirement already satisfied: tf-estimator-nightly~=2.7.0.dev in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (2.7.0.dev2021092408)\n",
            "Requirement already satisfied: tb-nightly~=2.7.0.a in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (2.7.0a20211003)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.40.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.7.4.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.37.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tf-nightly) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.7.0.a->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.7.0.a->tf-nightly) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.7.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.7.0.a->tf-nightly) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.7.0.a->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.7.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.7.0.a->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly~=2.7.0.a->tf-nightly) (3.5.0)\n",
            "Installing collected packages: gast\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.2.0\n",
            "    Uninstalling gast-0.2.0:\n",
            "      Successfully uninstalled gast-0.2.0\n",
            "Successfully installed gast-0.4.0\n",
            "Collecting gast==0.2.0\n",
            "  Using cached gast-0.2.0-py3-none-any.whl\n",
            "Installing collected packages: gast\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-nightly 2.8.0.dev20211003 requires gast<0.5.0,>=0.2.1, but you have gast 0.2.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires gast==0.4.0, but you have gast 0.2.0 which is incompatible.\n",
            "tensorflow-probability 0.13.0 requires gast>=0.3.2, but you have gast 0.2.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.0\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONCSUMnN6qzO"
      },
      "source": [
        "### 載入一代tf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i8Ag9kM6of9",
        "outputId": "a93adcb4-dadf-4e32-8d2a-4f42f7997169"
      },
      "source": [
        "%tensorflow_version 1.10\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.10`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD3wXVa07QiF"
      },
      "source": [
        "### 更改路徑"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GqmY9Ix7PXc"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/museGan\") #更改路徑\n",
        "dir='/content/drive/MyDrive/museGan'\n",
        "#os.getcwd() #查看當前路徑"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xDEfsqo4hop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc5d193-0d7a-4b1f-8af9-888334d752c8"
      },
      "source": [
        "\"\"\"This script performs inference from a trained model.\"\"\"\n",
        "\n",
        "import logging\n",
        "import argparse\n",
        "from pprint import pformat\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import tensorflow as tf\n",
        "from config import LOGLEVEL, LOG_FORMAT\n",
        "from data_predict_version import load_data, get_samples\n",
        "from model import Model\n",
        "from utils import make_sure_path_exists, load_yaml, update_not_none\n",
        "LOGGER = logging.getLogger(\"musegan.inference\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3497984/45929032 bytes (7.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6717440/45929032 bytes (14.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b10264576/45929032 bytes (22.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b13606912/45929032 bytes (29.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b17137664/45929032 bytes (37.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20267008/45929032 bytes (44.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23633920/45929032 bytes (51.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b27009024/45929032 bytes (58.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b30547968/45929032 bytes (66.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b33939456/45929032 bytes (73.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b37355520/45929032 bytes (81.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b40976384/45929032 bytes (89.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b44736512/45929032 bytes (97.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUMCnSjU55Q4"
      },
      "source": [
        "def parse_arguments(folderName):\n",
        "\n",
        "    #設定以哪個資料夾下的Model做預測\n",
        "    # predict_folder='exp/default_2/'\n",
        "    predict_folder = folderName\n",
        "\n",
        "    \"\"\"Parse and return the command line arguments.\"\"\"\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--result_dir',default=predict_folder,\n",
        "                        help=\"Directory where the results are saved.\")\n",
        "    parser.add_argument('--checkpoint_dir',default=predict_folder+'model/',\n",
        "                        help=\"Directory that contains checkpoints.\")\n",
        "    parser.add_argument('--params', '--params_file', '--params_file_path', default=predict_folder+'params.yaml',\n",
        "                        help=\"Path to the file that defines the \"\n",
        "                             \"hyperparameters.\")\n",
        "    parser.add_argument('--config',default=predict_folder+'config.yaml', help=\"Path to the configuration file.\")\n",
        "    parser.add_argument('--runs', type=int, default=\"1\",\n",
        "                        help=\"Times to run the inference process.\")\n",
        "    parser.add_argument('--rows', type=int, default=5,\n",
        "                        help=\"Number of images per row to be generated.\")\n",
        "    parser.add_argument('--columns', type=int, default=5,\n",
        "                        help=\"Number of images per column to be generated.\")\n",
        "    parser.add_argument('--lower', type=float, default=-2,\n",
        "                        help=\"Lower bound of the truncated normal random \"\n",
        "                             \"variables.\")\n",
        "    parser.add_argument('--upper', type=float, default=2,\n",
        "                        help=\"Upper bound of the truncated normal random \"\n",
        "                             \"variables.\")\n",
        "    parser.add_argument('--gpu', '--gpu_device_num', type=str, default=\"0\",\n",
        "                        help=\"The GPU device number to use.\")\n",
        "    #args = parser.parse_args()\n",
        "    # colab改成沒有輸入params，等等用指定的方式指定args\n",
        "    args = parser.parse_args(args=[])\n",
        "    return args"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxilHSwq57yo"
      },
      "source": [
        "def setup(folderName):\n",
        "    \"\"\"Parse command line arguments, load model parameters, load configurations\n",
        "    and setup environment.\"\"\"\n",
        "    # Parse the command line arguments\n",
        "    args = parse_arguments(folderName)\n",
        "\n",
        "    # Load parameters\n",
        "    # colab改成沒有輸入params，等等用指定的方式指定args\n",
        "    params = load_yaml(args.params)\n",
        "\n",
        "    # Load training configurations\n",
        "    config = load_yaml(args.config)\n",
        "    update_not_none(config, vars(args))\n",
        "\n",
        "    # Set unspecified schedule steps to default values\n",
        "    for target in (config['learning_rate_schedule'], config['slope_schedule']):\n",
        "        if target['start'] is None:\n",
        "            target['start'] = 0\n",
        "        if target['end'] is None:\n",
        "            target['end'] = config['steps']\n",
        "\n",
        "    # Make sure result directory exists\n",
        "    make_sure_path_exists(config['result_dir'])\n",
        "\n",
        "    # Setup GPUs\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = config['gpu']\n",
        "\n",
        "    return params, config"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XKNwrOi5-Ao"
      },
      "source": [
        "def inference_main(folderName):\n",
        "    \"\"\"Main function.\"\"\"\n",
        "    # Setup\n",
        "    logging.basicConfig(level=LOGLEVEL, format=LOG_FORMAT)\n",
        "    params, config = setup(folderName)\n",
        "    LOGGER.info(\"Using parameters:\\n%s\", pformat(params))\n",
        "    LOGGER.info(\"Using configurations:\\n%s\", pformat(config))\n",
        "\n",
        "    # ============================== Placeholders ==============================\n",
        "    placeholder_x = tf.placeholder(\n",
        "        tf.float32, shape=([None] + params['data_shape']))\n",
        "    placeholder_z = tf.placeholder(\n",
        "        tf.float32, shape=(None, params['latent_dim']))\n",
        "    placeholder_c = tf.placeholder(\n",
        "        tf.float32, shape=([None] + params['data_shape'][:-1] + [1]))\n",
        "    placeholder_suffix = tf.placeholder(tf.string)\n",
        "\n",
        "    # ================================= Model ==================================\n",
        "    # Create sampler configurations\n",
        "    sampler_config = {\n",
        "        'result_dir': config['result_dir'],\n",
        "        'image_grid': (config['rows'], config['columns']),\n",
        "        'suffix': placeholder_suffix, 'midi': config['midi'],\n",
        "        'colormap': np.array(config['colormap']).T,\n",
        "        'collect_save_arrays_op': config['save_array_samples'],\n",
        "        'collect_save_images_op': config['save_image_samples'],\n",
        "        'collect_save_pianorolls_op': config['save_pianoroll_samples']}\n",
        "\n",
        "    # Build model\n",
        "    model = Model(params)\n",
        "    if params.get('is_accompaniment'):\n",
        "        _ = model(\n",
        "            x=placeholder_x, c=placeholder_c, z=placeholder_z, mode='train',\n",
        "            params=params, config=config)\n",
        "        predict_nodes = model(\n",
        "            c=placeholder_c, z=placeholder_z, mode='predict', params=params,\n",
        "            config=sampler_config)\n",
        "    else:\n",
        "        _ = model(\n",
        "            x=placeholder_x, z=placeholder_z, mode='train', params=params,\n",
        "            config=config)\n",
        "        predict_nodes = model(\n",
        "            z=placeholder_z, mode='predict', params=params,\n",
        "            config=sampler_config)\n",
        "\n",
        "    # Get sampler op\n",
        "    sampler_op = tf.group([\n",
        "        predict_nodes[key] for key in (\n",
        "            'save_arrays_op', 'save_images_op', 'save_pianorolls_op')\n",
        "        if key in predict_nodes])\n",
        "\n",
        "    # ================================== Data ==================================\n",
        "    if params.get('is_accompaniment'):\n",
        "        data = load_data(config['data_source'], config['data_filename'])\n",
        "        print('predicted_data_issssss: ',data.shape)\n",
        "\n",
        "    # ========================== Session Preparation ===========================\n",
        "    # Get tensorflow session config\n",
        "    tf_config = tf.ConfigProto()\n",
        "    tf_config.gpu_options.allow_growth = True\n",
        "\n",
        "    # Create saver to restore variables\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    # =========================== Tensorflow Session ===========================\n",
        "    with tf.Session(config=tf_config) as sess:\n",
        "\n",
        "        # Restore the latest checkpoint\n",
        "        LOGGER.info(\"Restoring the latest checkpoint.\")\n",
        "        with open(os.path.join(config['checkpoint_dir'], 'checkpoint')) as f:\n",
        "            checkpoint_name = os.path.basename(\n",
        "                f.readline().split()[1].strip('\"'))\n",
        "        checkpoint_path = os.path.realpath(\n",
        "            os.path.join(config['checkpoint_dir'], checkpoint_name))\n",
        "        print('checkpoint_path is:::::',checkpoint_path)\n",
        "        saver.restore(sess, checkpoint_path)\n",
        "\n",
        "        # Run sampler op\n",
        "        for i in range(config['runs']):\n",
        "            feed_dict_sampler = {\n",
        "                placeholder_z: scipy.stats.truncnorm.rvs(\n",
        "                    config['lower'], config['upper'], size=(\n",
        "                        (config['rows'] * config['columns']),\n",
        "                        params['latent_dim'])),\n",
        "                placeholder_suffix: str(i)}  \n",
        "            if params.get('is_accompaniment'):\n",
        "                # sample_x = get_samples(\n",
        "                #     (config['rows'] * config['columns']), data,\n",
        "                #     use_random_transpose=config['use_random_transpose'])\n",
        "                # feed_dict_sampler[placeholder_c] = np.expand_dims(\n",
        "                #     sample_x[..., params['condition_track_idx']], -1)\n",
        "                feed_dict_sampler[placeholder_c]=data\n",
        "                # code in \"if(i<1)\" all are added py paul\n",
        "                if(i<1):\n",
        "                    tmp = feed_dict_sampler[placeholder_c]\n",
        "                    print(i,tmp.shape)\n",
        "                    for j in range(24):  \n",
        "                        print(feed_dict_sampler[placeholder_c].shape)  \n",
        "                        feed_dict_sampler[placeholder_c]=np.vstack([feed_dict_sampler[placeholder_c],tmp])                 \n",
        "                    \t\n",
        "                    #print('before:\\n',sample_x.shape,'\\nAfter:\\n', sample_x[..., params['condition_track_idx']].shape)\n",
        "                    #print('params[\\'condition_track_idx\\']:',params['condition_track_idx'])\n",
        "                    print('feed_dict_sampler:\\n',feed_dict_sampler[placeholder_c].shape)\n",
        "            sess.run(sampler_op, feed_dict=feed_dict_sampler)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7xl9ko8Sh6D"
      },
      "source": [
        "from pypianoroll import Multitrack\n",
        "\n",
        "def get_midi(route):\n",
        "  midi_file = Multitrack(route+'fake_x_bernoulli_sampling_0.npz')\n",
        "  midi_file.write(route+'fake_x_0.mid')\n",
        "  return midi_file"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I11r6ouGVUwJ"
      },
      "source": [
        "\n",
        "def predict_trackCondition():\n",
        "  folderName = 'exp/accompaniment/piano/'\n",
        "  inference_main(folderName)\n",
        "\n",
        "def predict_Normal(genre):\n",
        "\n",
        "  folderName = 'exp/'+genre+'/'\n",
        "  inference_main(folderName)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFCwxCkdmhGh"
      },
      "source": [
        "def get_genre(genre):\n",
        "  if(genre is 0):\n",
        "    return 'normal_pop'\n",
        "  if(genre is 1):\n",
        "    return 'default_2'\n",
        "  if(genre is 2):\n",
        "    return 'normal_electronic'\n",
        "  if(genre is 3):\n",
        "    return 'normal_origin'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOD0zA8RXMDX"
      },
      "source": [
        "# API 拿midi檔\n",
        "### flask & ngrok source : https://aishuafei.com/google-colab-flask/\n",
        "### midi:https://stackoverflow.com/questions/28121776/how-do-i-allow-users-to-download-a-midi-file-with-flask-without-getting-a-0-byte\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDyzwYDtTgXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a43eab-491a-4f6b-8b64-7e845fd78240"
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask,send_file,request\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "\n",
        "@app.route(\"/trackCondition\", methods=['GET', 'POST'])\n",
        "def trackCondition():\n",
        "\n",
        "  # request file\n",
        "  file = request.files['midiFile']\n",
        "\n",
        "  base='/content/drive/MyDrive/museGan/exp/accompaniment/piano/pianorolls/fake_x_bernoulli_sampling/'\n",
        "  predict_trackCondition()\n",
        "  midi = get_midi(base)\n",
        "  new_file = open(base+'fake_x_0.mid', 'rb')\n",
        "  return send_file(new_file, mimetype='audio/midi')\n",
        "  \n",
        "@app.route(\"/random\", methods=['GET', 'POST'])\n",
        "def ramdom():\n",
        "  # base param\n",
        "  base ='/content/drive/MyDrive/museGan/exp/'\n",
        "  lastParam = '/pianorolls/fake_x_bernoulli_sampling/'\n",
        "\n",
        "  #request data\n",
        "  rJson = request.json\n",
        "  print('genre -> ',rJson)\n",
        "  genre_num = rJson['genre']#0,1,2\n",
        "  \n",
        "  #print('\\ngenre_num : ',genre_num,'\\n')\n",
        "  \n",
        "  genre = get_genre(genre_num)\n",
        "  \n",
        "  predict_Normal(genre)\n",
        "  midi = get_midi(base+genre+lastParam)\n",
        "  new_file = open(base+genre+lastParam+'fake_x_0.mid', 'rb')\n",
        "  return send_file(new_file, mimetype='audio/midi')\n",
        "  \n",
        "app.run()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
            "werkzeug             INFO      * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://290f-35-236-194-106.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "musegan.inference    INFO     Using parameters:\n",
            "{'beat_resolution': 12,\n",
            " 'condition_track_idx': 1,\n",
            " 'data_shape': [4, 48, 84, 5],\n",
            " 'is_accompaniment': True,\n",
            " 'is_conditional': True,\n",
            " 'latent_dim': 128,\n",
            " 'nets': {'discriminator': 'default', 'generator': 'accompaniment'},\n",
            " 'use_binary_neurons': False}\n",
            "musegan.inference    INFO     Using configurations:\n",
            "{'adam': {'beta1': 0.5, 'beta2': 0.9},\n",
            " 'batch_size': 64,\n",
            " 'checkpoint_dir': 'exp/accompaniment/piano/model/',\n",
            " 'colormap': [[1.0, 0.0, 0.0],\n",
            "              [1.0, 0.5, 0.0],\n",
            "              [0.0, 1.0, 0.0],\n",
            "              [0.0, 0.0, 1.0],\n",
            "              [0.0, 0.5, 1.0]],\n",
            " 'columns': 5,\n",
            " 'config': 'exp/accompaniment/piano/config.yaml',\n",
            " 'data_filename': 'predict_input_data',\n",
            " 'data_root': './',\n",
            " 'data_source': 'npy',\n",
            " 'evaluate_steps': 100,\n",
            " 'gan_loss_type': 'wasserstein',\n",
            " 'gpu': '0',\n",
            " 'initial_learning_rate': 0.001,\n",
            " 'learning_rate_schedule': {'end': 50000, 'end_value': 0.0, 'start': 45000},\n",
            " 'log_loss_steps': 100,\n",
            " 'lower': -2,\n",
            " 'midi': {'is_drums': [1, 0, 0, 0, 0],\n",
            "          'lowest_pitch': 24,\n",
            "          'programs': [0, 0, 25, 33, 48],\n",
            "          'tempo': 100},\n",
            " 'n_dis_updates_per_gen_update': 5,\n",
            " 'n_jobs': 20,\n",
            " 'params': 'exp/accompaniment/piano/params.yaml',\n",
            " 'result_dir': 'exp/accompaniment/piano/',\n",
            " 'rows': 5,\n",
            " 'runs': 1,\n",
            " 'sample_grid': [8, 8],\n",
            " 'save_array_samples': True,\n",
            " 'save_checkpoint_steps': 10000,\n",
            " 'save_image_samples': True,\n",
            " 'save_pianoroll_samples': True,\n",
            " 'save_samples_steps': 100,\n",
            " 'save_summaries_steps': 0,\n",
            " 'slope_schedule': {'end': 50000, 'end_value': 5.0, 'start': 10000},\n",
            " 'steps': 50000,\n",
            " 'upper': 2,\n",
            " 'use_gradient_penalties': True,\n",
            " 'use_learning_rate_decay': True,\n",
            " 'use_random_transpose': False,\n",
            " 'use_slope_annealing': False,\n",
            " 'use_train_test_split': False}\n",
            "model                INFO     Building model.\n",
            "model                INFO     Building training nodes.\n",
            "model                INFO     Building losses.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of true data:  (?, 4, 48, 84, 5)\n",
            "Shape of fake data:  (?, 4, 48, 84, 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model                INFO     Building training ops.\n",
            "model                INFO     Building summaries.\n",
            "model                INFO     Building prediction nodes.\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1025, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 869, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 608, in format\n",
            "    record.message = record.getMessage()\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 369, in getMessage\n",
            "    msg = msg % self.args\n",
            "TypeError: not all arguments converted during string formatting\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 890, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/socketserver.py\", line 650, in process_request_thread\n",
            "    self.finish_request(request, client_address)\n",
            "  File \"/usr/lib/python3.7/socketserver.py\", line 360, in finish_request\n",
            "    self.RequestHandlerClass(request, client_address, self)\n",
            "  File \"/usr/lib/python3.7/socketserver.py\", line 720, in __init__\n",
            "    self.handle()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/werkzeug/serving.py\", line 345, in handle\n",
            "    BaseHTTPRequestHandler.handle(self)\n",
            "  File \"/usr/lib/python3.7/http/server.py\", line 426, in handle\n",
            "    self.handle_one_request()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/werkzeug/serving.py\", line 379, in handle_one_request\n",
            "    return self.run_wsgi()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/werkzeug/serving.py\", line 323, in run_wsgi\n",
            "    execute(self.server.app)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/werkzeug/serving.py\", line 312, in execute\n",
            "    application_iter = app(environ, start_response)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 2464, in __call__\n",
            "    return self.wsgi_app(environ, start_response)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 2447, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1936, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"<ipython-input-18-331b9da09679>\", line 13, in trackCondition\n",
            "    predict_trackCondition()\n",
            "  File \"<ipython-input-12-0eaeb84173df>\", line 4, in predict_trackCondition\n",
            "    inference_main(folderName)\n",
            "  File \"<ipython-input-10-ef7cac5fb4d8>\", line 54, in inference_main\n",
            "    data = load_data(config['data_source'], config['data_filename'])\n",
            "  File \"/content/drive/MyDrive/museGan/data_predict_version.py\", line 34, in load_data\n",
            "    LOGGER.info('root is : ',os.getcwd())\n",
            "Message: 'root is : '\n",
            "Arguments: ('/content/drive/My Drive/museGan',)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filename: filename\n",
            "root is :  /content/drive/MyDrive/museGan\n",
            "/content/drive/MyDrive/museGan\n",
            "predicted_data_issssss:  (1, 4, 48, 84, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "musegan.inference    INFO     Restoring the latest checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint_path is::::: /content/drive/MyDrive/museGan/exp/accompaniment/piano/model/model.ckpt-300450\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/museGan/exp/accompaniment/piano/model/model.ckpt-300450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tensorflow           INFO     Restoring parameters from /content/drive/MyDrive/museGan/exp/accompaniment/piano/model/model.ckpt-300450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (1, 4, 48, 84, 1)\n",
            "(1, 4, 48, 84, 1)\n",
            "(2, 4, 48, 84, 1)\n",
            "(3, 4, 48, 84, 1)\n",
            "(4, 4, 48, 84, 1)\n",
            "(5, 4, 48, 84, 1)\n",
            "(6, 4, 48, 84, 1)\n",
            "(7, 4, 48, 84, 1)\n",
            "(8, 4, 48, 84, 1)\n",
            "(9, 4, 48, 84, 1)\n",
            "(10, 4, 48, 84, 1)\n",
            "(11, 4, 48, 84, 1)\n",
            "(12, 4, 48, 84, 1)\n",
            "(13, 4, 48, 84, 1)\n",
            "(14, 4, 48, 84, 1)\n",
            "(15, 4, 48, 84, 1)\n",
            "(16, 4, 48, 84, 1)\n",
            "(17, 4, 48, 84, 1)\n",
            "(18, 4, 48, 84, 1)\n",
            "(19, 4, 48, 84, 1)\n",
            "(20, 4, 48, 84, 1)\n",
            "(21, 4, 48, 84, 1)\n",
            "(22, 4, 48, 84, 1)\n",
            "(23, 4, 48, 84, 1)\n",
            "(24, 4, 48, 84, 1)\n",
            "feed_dict_sampler:\n",
            " (25, 4, 48, 84, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [04/Oct/2021 10:20:46] \"\u001b[37mPOST /trackCondition HTTP/1.1\u001b[0m\" 200 -\n",
            "werkzeug             INFO     127.0.0.1 - - [04/Oct/2021 10:20:46] \"\u001b[37mPOST /trackCondition HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    }
  ]
}